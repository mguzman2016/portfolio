{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "186374d8",
   "metadata": {},
   "source": [
    "# Twitter Sentiment Data Exploration\n",
    "\n",
    "This notebook was created to explore the data present in the Twitter Sentiment dataset ([dummy URL](https://www.kaggle.com/datasets/jp797498e/twitter-entity-sentiment-analysis)), with the goal of understanding the data and how it influences the final sentiment results expressed by users.\n",
    "\n",
    "For starters, we'll load the necessary libraries needed for this project, as you can see we have already a training and validation dataset available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "65983a67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Tweet ID",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Entity",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Sentiment",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Tweet content",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "ref": "60cfdcf1-bfd1-481b-9a29-dd355e53c90c",
       "rows": [
        [
         "0",
         "2401",
         "Borderlands",
         "Positive",
         "im getting on borderlands and i will murder you all ,"
        ],
        [
         "1",
         "2401",
         "Borderlands",
         "Positive",
         "I am coming to the borders and I will kill you all,"
        ],
        [
         "2",
         "2401",
         "Borderlands",
         "Positive",
         "im getting on borderlands and i will kill you all,"
        ],
        [
         "3",
         "2401",
         "Borderlands",
         "Positive",
         "im coming on borderlands and i will murder you all,"
        ],
        [
         "4",
         "2401",
         "Borderlands",
         "Positive",
         "im getting on borderlands 2 and i will murder you me all,"
        ],
        [
         "5",
         "2401",
         "Borderlands",
         "Positive",
         "im getting into borderlands and i can murder you all,"
        ],
        [
         "6",
         "2402",
         "Borderlands",
         "Positive",
         "So I spent a few hours making something for fun. . . If you don't know I am a HUGE @Borderlands fan and Maya is one of my favorite characters. So I decided to make myself a wallpaper for my PC. . Here is the original image versus the creation I made :) Enjoy! pic.twitter.com/mLsI5wf9Jg"
        ],
        [
         "7",
         "2402",
         "Borderlands",
         "Positive",
         "So I spent a couple of hours doing something for fun... If you don't know that I'm a huge @ Borderlands fan and Maya is one of my favorite characters, I decided to make a wallpaper for my PC.. Here's the original picture compared to the creation I made:) Have fun! pic.twitter.com / mLsI5wf9Jg"
        ],
        [
         "8",
         "2402",
         "Borderlands",
         "Positive",
         "So I spent a few hours doing something for fun... If you don't know I'm a HUGE @ Borderlands fan and Maya is one of my favorite characters."
        ],
        [
         "9",
         "2402",
         "Borderlands",
         "Positive",
         "So I spent a few hours making something for fun. . . If you don't know I am a HUGE RhandlerR fan and Maya is one of my favorite characters. So I decided to make myself a wallpaper for my PC. . Here is the original image versus the creation I made :) Enjoy! pic.twitter.com/mLsI5wf9Jg"
        ],
        [
         "10",
         "2402",
         "Borderlands",
         "Positive",
         "2010 So I spent a few hours making something for fun. . . If you don't know I am a HUGE RhandlerR fan and Maya is one of my favorite characters. So I decided to make myself a wallpaper for my PC. . Here is the original image versus the creation I made :) Enjoy! pic.twitter.com/mLsI5wf9Jg"
        ],
        [
         "11",
         "2402",
         "Borderlands",
         "Positive",
         "was"
        ],
        [
         "12",
         "2403",
         "Borderlands",
         "Neutral",
         "Rock-Hard La Varlope, RARE & POWERFUL, HANDSOME JACKPOT, Borderlands 3 (Xbox) dlvr.it/RMTrgF  "
        ],
        [
         "13",
         "2403",
         "Borderlands",
         "Neutral",
         "Rock-Hard La Varlope, RARE & POWERFUL, HANDSOME JACKPOT, Borderlands 3 (Xbox) dlvr.it / RMTrgF"
        ],
        [
         "14",
         "2403",
         "Borderlands",
         "Neutral",
         "Rock-Hard La Varlope, RARE & POWERFUL, HANDSOME JACKPOT, Borderlands 3 (Xbox) dfr.it / RMTrgF"
        ],
        [
         "15",
         "2403",
         "Borderlands",
         "Neutral",
         "Rock-Hard La Vita, RARE BUT POWERFUL, HANDSOME JACKPOT, Borderlands 1 (Xbox) dlvr.it/RMTrgF"
        ],
        [
         "16",
         "2403",
         "Borderlands",
         "Neutral",
         "Live Rock - Hard music La la Varlope, RARE & the POWERFUL, Live HANDSOME i JACKPOT, Borderlands 3 ( Sega Xbox ) dlvr. From it / e RMTrgF"
        ],
        [
         "17",
         "2403",
         "Borderlands",
         "Neutral",
         "I-Hard like me, RARE LONDON DE, HANDSOME 2011, Borderlands 3 (Xbox) dlvr.it/RMTrgF"
        ],
        [
         "18",
         "2404",
         "Borderlands",
         "Positive",
         "that was the first borderlands session in a long time where i actually had a really satisfying combat experience. i got some really good kills"
        ],
        [
         "19",
         "2404",
         "Borderlands",
         "Positive",
         "this was the first Borderlands session in a long time where i actually had a really satisfying fighting experience. i got some really good kills"
        ],
        [
         "20",
         "2404",
         "Borderlands",
         "Positive",
         "that was the first borderlands session in a long time where i actually had a really satisfying combat experience. i got some really good kills"
        ],
        [
         "21",
         "2404",
         "Borderlands",
         "Positive",
         "that was the first borderlands session in a long time where i actually enjoyed a really satisfying combat experience. i got some rather good kills"
        ],
        [
         "22",
         "2404",
         "Borderlands",
         "Positive",
         "that I was the first real borderlands session in a nice long wait time where i actually had a really satisfying combat experience. and i got some really good kills"
        ],
        [
         "23",
         "2404",
         "Borderlands",
         "Positive",
         "that was the first borderlands session in a hot row where i actually had a really bad combat experience. i did some really good kills"
        ],
        [
         "24",
         "2405",
         "Borderlands",
         "Negative",
         "the biggest dissappoinment in my life came out a year ago fuck borderlands 3"
        ],
        [
         "25",
         "2405",
         "Borderlands",
         "Negative",
         "The biggest disappointment of my life came a year ago."
        ],
        [
         "26",
         "2405",
         "Borderlands",
         "Negative",
         "The biggest disappointment of my life came a year ago."
        ],
        [
         "27",
         "2405",
         "Borderlands",
         "Negative",
         "the biggest dissappoinment in my life coming out a year ago fuck borderlands 3"
        ],
        [
         "28",
         "2405",
         "Borderlands",
         "Negative",
         "For the biggest male dissappoinment in my life came hanging out a year time ago fuck borderlands 3"
        ],
        [
         "29",
         "2405",
         "Borderlands",
         "Negative",
         "the biggest dissappoinment in my life came back last year ago fuck borderlands last"
        ],
        [
         "30",
         "2406",
         "Borderlands",
         "Positive",
         "WE FINISHED BORDERLANDS 3 FINALLY YAS! Thank you for hanging out everyone! It was fun. I will try to stream tomorrow but if not I might so some IRL streams while awayu. We shall see. Thank you so much for the raids @mompou_mumpow @MegaMagwitch and @KfdMitch."
        ],
        [
         "31",
         "2406",
         "Borderlands",
         "Positive",
         "WE FINALLY FINALLY FIND BORDERLANDS 3 YES! Thank you all for hanging out! It was fun. I'll try to stream tomorrow, but if not, maybe some IRL streams. We'll see. Thanks for the raids @ mompou _ mumpow @ MegaMagwitch and @ KfdMitch."
        ],
        [
         "32",
         "2406",
         "Borderlands",
         "Positive",
         "Thank you for hanging up everyone! It was fun. I'll try to get a haircut tomorrow, but if it wasn't for me, some IRL streams would still be in Hawaii. We'll see. Thank you so much for the @ mompou _ mumpow @ MegaMagwife and @ fendMitch raids."
        ],
        [
         "33",
         "2406",
         "Borderlands",
         "Positive",
         "WE FINISHED BORDERLANDS 3 UPDATE YAS! Thank you for hanging out guys! It was fun. I will try to stream and even if not I might so some IRL streams while awayu. We shall go. Thank you so much for the raids @mompou_mumpow @MegaMagwitch and Hope."
        ],
        [
         "34",
         "2406",
         "Borderlands",
         "Positive",
         "WE FINISHED BORDERLANDS 3 AND FINALLY YAS! Thank you everyone for hanging out everyone! It was fun. I will try to make stream tomorrow but if not I might make so some IRL streams while awayu. 10 We never shall see. Thank you both so... much for the raids @mompou_mumpow or @MegaMagwitch and 4 @KfdMitch."
        ],
        [
         "35",
         "2406",
         "Borderlands",
         "Positive",
         "WE FINISHED BORDERLANDS 3 FINALLY YAS! Hey you for hanging out so! It was fun. I will try that stream tomorrow and if not I might use some IRL streams from awayu. We shall see. Thank you so much how many raids @mompou_mumpow did and their."
        ],
        [
         "36",
         "2407",
         "Borderlands",
         "Negative",
         "Man Gearbox really needs to fix this dissapointing drops in the new Borderlands 3 DLC cant be fine to farm bosses on Mayhem 10 to get 1 legendary drop while anywhere else i get 6-10 drops. . Really sucks alot"
        ],
        [
         "37",
         "2407",
         "Borderlands",
         "Negative",
         "Man Gearbox really needs to fix these disappointing drops in the new Borderlands 3 DLC for farm bosses on Mayhem 10 to get a legendary drop, while I get 6-10 drops elsewhere."
        ],
        [
         "38",
         "2407",
         "Borderlands",
         "Negative",
         "Man Gearbox really needs to fix this disssapointing drops in the new Borderlands 3 DLC cant be fine to farm bosses on Mayhem 10 to get 1 legendary drop while elsewhere i get 6-10 drops... Really sucks alot"
        ],
        [
         "39",
         "2407",
         "Borderlands",
         "Negative",
         "Man Bethesda really needs to fix this dissapointing drops and the new Borderlands 3 It cant be fine to farm bosses on Mayhem 10 to get 1 legendary drop while anywhere else i get 6-10 drops.. Really sucks..."
        ],
        [
         "40",
         "2407",
         "Borderlands",
         "Negative",
         "Man Gearbox really needs to fix this dissapointing drops in the completely new Borderlands 3 Days DLC i cant e be fine having to be farm bosses on Mayhem 10 to e get 1 legendary foot drop while anywhere else i get 6 - 10 drops.. It Really sucks to alot"
        ],
        [
         "41",
         "2407",
         "Borderlands",
         "Negative",
         "<unk> Gearbox really time to fix this 10 drops in the new Borderlands 3 DLC or be fine to force bosses on Mayhem 10 to get a legendary drop while everyone else i get 6-10 drops.. Really needs alot"
        ],
        [
         "42",
         "2408",
         "Borderlands",
         "Neutral",
         "Check out this epic streamer!.  "
        ],
        [
         "43",
         "2408",
         "Borderlands",
         "Neutral",
         "Check out this epic streamer!."
        ],
        [
         "44",
         "2408",
         "Borderlands",
         "Neutral",
         "Watch this epic striptease!."
        ],
        [
         "45",
         "2408",
         "Borderlands",
         "Neutral",
         "Check out our epic streamer!."
        ],
        [
         "46",
         "2408",
         "Borderlands",
         "Neutral",
         "Check out this big epic streamer!."
        ],
        [
         "47",
         "2408",
         "Borderlands",
         "Neutral",
         "Check<unk> this epic streamer!."
        ],
        [
         "48",
         "2409",
         "Borderlands",
         "Neutral",
         "Blaming Sight for Tardiness! A little bit of borderlands. I got called in early for work tomorrow so I can't make up time. Sorry my loves .  twitch.tv/punnisenpai"
        ],
        [
         "49",
         "2409",
         "Borderlands",
         "Neutral",
         "A bit of borderland. I was called to work tomorrow morning, so I can't catch up. Sorry, my love. twitch.tv / punnisenpai"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 74682
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet ID</th>\n",
       "      <th>Entity</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Tweet content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands and i will murder yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>I am coming to the borders and I will kill you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands and i will kill you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im coming on borderlands and i will murder you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands 2 and i will murder ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74677</th>\n",
       "      <td>9200</td>\n",
       "      <td>Nvidia</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Just realized that the Windows partition of my...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74678</th>\n",
       "      <td>9200</td>\n",
       "      <td>Nvidia</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Just realized that my Mac window partition is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74679</th>\n",
       "      <td>9200</td>\n",
       "      <td>Nvidia</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Just realized the windows partition of my Mac ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74680</th>\n",
       "      <td>9200</td>\n",
       "      <td>Nvidia</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Just realized between the windows partition of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74681</th>\n",
       "      <td>9200</td>\n",
       "      <td>Nvidia</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Just like the windows partition of my Mac is l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>74682 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Tweet ID       Entity Sentiment  \\\n",
       "0          2401  Borderlands  Positive   \n",
       "1          2401  Borderlands  Positive   \n",
       "2          2401  Borderlands  Positive   \n",
       "3          2401  Borderlands  Positive   \n",
       "4          2401  Borderlands  Positive   \n",
       "...         ...          ...       ...   \n",
       "74677      9200       Nvidia  Positive   \n",
       "74678      9200       Nvidia  Positive   \n",
       "74679      9200       Nvidia  Positive   \n",
       "74680      9200       Nvidia  Positive   \n",
       "74681      9200       Nvidia  Positive   \n",
       "\n",
       "                                           Tweet content  \n",
       "0      im getting on borderlands and i will murder yo...  \n",
       "1      I am coming to the borders and I will kill you...  \n",
       "2      im getting on borderlands and i will kill you ...  \n",
       "3      im coming on borderlands and i will murder you...  \n",
       "4      im getting on borderlands 2 and i will murder ...  \n",
       "...                                                  ...  \n",
       "74677  Just realized that the Windows partition of my...  \n",
       "74678  Just realized that my Mac window partition is ...  \n",
       "74679  Just realized the windows partition of my Mac ...  \n",
       "74680  Just realized between the windows partition of...  \n",
       "74681  Just like the windows partition of my Mac is l...  \n",
       "\n",
       "[74682 rows x 4 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import kagglehub\n",
    "\n",
    "path = kagglehub.dataset_download(\"jp797498e/twitter-entity-sentiment-analysis\")\n",
    "training_path = f\"{path}/twitter_training.csv\"\n",
    "validation_path = f\"{path}/twitter_validation.csv\"\n",
    "\n",
    "df_train = pd.read_csv(\n",
    "    training_path,\n",
    "    header=None,\n",
    "    names=['Tweet ID', 'Entity', 'Sentiment','Tweet content']\n",
    ")\n",
    "\n",
    "df_test = pd.read_csv(\n",
    "    validation_path,\n",
    "    header=None,\n",
    "    names=['Tweet ID', 'Entity', 'Sentiment','Tweet content']\n",
    ")\n",
    "\n",
    "df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b82e9c",
   "metadata": {},
   "source": [
    "Once data has been loaded let's have a look at the percentage of missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a8181f19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "missing_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "missing_pct",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "cdd05a27-5a39-4fa9-b5e4-7eb2ccfd2355",
       "rows": [
        [
         "Tweet content",
         "686",
         "0.9185613668621622"
        ],
        [
         "Tweet ID",
         "0",
         "0.0"
        ],
        [
         "Entity",
         "0",
         "0.0"
        ],
        [
         "Sentiment",
         "0",
         "0.0"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 4
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>missing_count</th>\n",
       "      <th>missing_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Tweet content</th>\n",
       "      <td>686</td>\n",
       "      <td>0.918561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tweet ID</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Entity</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sentiment</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               missing_count  missing_pct\n",
       "Tweet content            686     0.918561\n",
       "Tweet ID                   0     0.000000\n",
       "Entity                     0     0.000000\n",
       "Sentiment                  0     0.000000"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_count = df_train.isna().sum()\n",
    "missing_pct = df_train.isna().mean() * 100\n",
    "missing_stats = (\n",
    "    pd.DataFrame({\n",
    "        'missing_count': missing_count,\n",
    "        'missing_pct': missing_pct\n",
    "    })\n",
    "    .sort_values('missing_count', ascending=False)\n",
    ")\n",
    "\n",
    "missing_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8baafa78",
   "metadata": {},
   "source": [
    "There are just a few of rows with missing values, based on this we'll drop both duplicates and na values, depending on the performance of the models we might wanna add extra rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b44d7202",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.drop_duplicates()\n",
    "df_train = df_train.dropna()\n",
    "\n",
    "df_test = df_test.drop_duplicates()\n",
    "df_test = df_test.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18cdf37c",
   "metadata": {},
   "source": [
    "Now that everything has been handled let's quickly test a few models, and get an idea of how they work just based on their default parameters, also we can check if the \"Entity\" column actually has any impact in the performance of the model.\n",
    "Once they are working we can setup a more robust cvsearch to adjust parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7575f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/07 21:52:23 WARNING mlflow.utils.autologging_utils: MLflow sklearn autologging is known to be compatible with 1.3.0 <= scikit-learn <= 1.7.0, but the installed version is 1.7.1. If you encounter errors during autologging, try upgrading / downgrading scikit-learn to a compatible version, or try upgrading MLflow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Tweet content'], dtype='object')\n",
      "ColumnTransformer(transformers=[('text', Pipeline(steps=[('vect', None)]),\n",
      "                                 'Tweet content')])\n",
      "Fitting to pipeline\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/miguel/anaconda3/envs/generative_ai/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [21:52:43] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/miguel/anaconda3/envs/generative_ai/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [21:52:43] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/miguel/anaconda3/envs/generative_ai/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [21:52:43] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/miguel/anaconda3/envs/generative_ai/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [21:52:44] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/miguel/anaconda3/envs/generative_ai/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [21:52:44] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/miguel/anaconda3/envs/generative_ai/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [21:52:47] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/miguel/anaconda3/envs/generative_ai/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [21:53:01] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/miguel/anaconda3/envs/generative_ai/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [21:53:22] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/miguel/anaconda3/envs/generative_ai/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [21:53:39] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/miguel/anaconda3/envs/generative_ai/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [21:53:59] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "2025/08/07 21:57:15 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/home/miguel/anaconda3/envs/generative_ai/lib/python3.10/site-packages/mlflow/sklearn/utils.py:846: UserWarning: Top 5 child runs will be created based on ordering in rank_test_accuracy column.  You can choose not to limit the number of child runs created by setting `max_tuning_runs=None`.\"\n",
      "2025/08/07 21:57:15 INFO mlflow.sklearn.utils: Logging the 5 best runs, 3 runs will be omitted.\n",
      "2025/08/07 21:57:15 WARNING mlflow.utils.autologging_utils: MLflow sklearn autologging is known to be compatible with 1.3.0 <= scikit-learn <= 1.7.0, but the installed version is 1.7.1. If you encounter errors during autologging, try upgrading / downgrading scikit-learn to a compatible version, or try upgrading MLflow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run rare-shad-684 at: http://localhost:5000/#/experiments/1/runs/f34c2f546ac34f228d5787302126413d\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/1\n",
      "🏃 View run victorious-perch-246 at: http://localhost:5000/#/experiments/1/runs/6f02e5567cdd4d6ba330d9ed303a84a1\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/1\n",
      "🏃 View run unleashed-whale-244 at: http://localhost:5000/#/experiments/1/runs/1c809e2772f24348b67c39d731e82f38\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/1\n",
      "🏃 View run dapper-squirrel-182 at: http://localhost:5000/#/experiments/1/runs/e8177464b5a94233bea33b8b1c4b4870\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/1\n",
      "🏃 View run casual-wolf-596 at: http://localhost:5000/#/experiments/1/runs/345e30bc02bf49dcbfa95dc626482c58\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/1\n",
      "🏃 View run masked-goat-126 at: http://localhost:5000/#/experiments/1/runs/3f83a7b3fdd342b391d3d31853dc7daa\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/1\n",
      "Best estimator: Pipeline(steps=[('preprocessor',\n",
      "                 ColumnTransformer(transformers=[('text',\n",
      "                                                  Pipeline(steps=[('vect',\n",
      "                                                                   CountVectorizer())]),\n",
      "                                                  'Tweet content')])),\n",
      "                ('clf', MultinomialNB())])\n",
      "Best CV score: 0.5579555573428071\n",
      "Estimating performance on test set\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.88      0.82       266\n",
      "           1       0.80      0.90      0.85       277\n",
      "           2       0.93      0.78      0.85       457\n",
      "\n",
      "    accuracy                           0.84      1000\n",
      "   macro avg       0.83      0.85      0.84      1000\n",
      "weighted avg       0.85      0.84      0.84      1000\n",
      "\n",
      "Index(['Tweet content', 'Entity'], dtype='object')\n",
      "ColumnTransformer(transformers=[('text', Pipeline(steps=[('vect', None)]),\n",
      "                                 'Tweet content'),\n",
      "                                ('entity',\n",
      "                                 OneHotEncoder(handle_unknown='ignore'),\n",
      "                                 ['Entity'])])\n",
      "Fitting to pipeline\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/miguel/anaconda3/envs/generative_ai/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [21:57:35] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/miguel/anaconda3/envs/generative_ai/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [21:57:35] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/miguel/anaconda3/envs/generative_ai/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [21:57:35] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/miguel/anaconda3/envs/generative_ai/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [21:57:36] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/miguel/anaconda3/envs/generative_ai/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [21:57:36] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/miguel/anaconda3/envs/generative_ai/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [21:57:36] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/miguel/anaconda3/envs/generative_ai/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [21:57:52] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/miguel/anaconda3/envs/generative_ai/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [21:58:11] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/miguel/anaconda3/envs/generative_ai/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [21:58:26] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/miguel/anaconda3/envs/generative_ai/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [21:58:45] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    }
   ],
   "source": [
    "import mlflow, mlflow.sklearn\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "def sentiment_encoding(sentiment):\n",
    "    sentiments = {\n",
    "        'Positive': 1,\n",
    "        'Negative': 0,\n",
    "        'Neutral': 2,\n",
    "        # Neutral and irrelevant are treated equally as per the comment\n",
    "        # on the source dataset (see link at the start of the notebook):\n",
    "        # \"We regard messages that are not relevant to the entity (i.e. Irrelevant) as Neutral.\"\n",
    "        'Irrelevant': 2\n",
    "    }\n",
    "    \n",
    "    return sentiments[sentiment]\n",
    "\n",
    "# Pre-processing, drop tweet id\n",
    "text_pipeline = Pipeline([\n",
    "    ('vect', None)\n",
    "])\n",
    "\n",
    "fields = {\n",
    "    'Tweet content': ('text', text_pipeline, 'Tweet content'),\n",
    "    'Entity': ('entity', OneHotEncoder(handle_unknown='ignore'), ['Entity'])\n",
    "}\n",
    "\n",
    "fields_to_test = []\n",
    "for field_name in fields.keys():\n",
    "    fields_to_test.append(field_name)\n",
    "\n",
    "    X_train = df_train[fields_to_test]\n",
    "    # X_train = df_train[['Tweet content']]\n",
    "    y_train = df_train['Sentiment'].map(sentiment_encoding)\n",
    "\n",
    "    X_test = df_test[fields_to_test]\n",
    "    # X_test = df_test[['Tweet content']]\n",
    "    y_test = df_test['Sentiment'].map(sentiment_encoding)\n",
    "\n",
    "    preprocessor = ColumnTransformer(list(fields[field] for field in fields_to_test))\n",
    "\n",
    "    # preprocessor = ColumnTransformer([\n",
    "    #     ('text', text_pipeline, 'Tweet content'),\n",
    "    # ])\n",
    "\n",
    "    print(X_train.columns)\n",
    "    print(preprocessor)\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('clf', None)\n",
    "    ])\n",
    "\n",
    "    param_grid = [\n",
    "        {\n",
    "            'preprocessor__text__vect': [TfidfVectorizer(), CountVectorizer()],\n",
    "            'clf': [RandomForestClassifier()],\n",
    "        },\n",
    "        {\n",
    "            'preprocessor__text__vect': [TfidfVectorizer(), CountVectorizer()],\n",
    "            'clf': [LogisticRegression(max_iter=1000)],\n",
    "        },\n",
    "        {\n",
    "            'preprocessor__text__vect': [TfidfVectorizer(), CountVectorizer()],\n",
    "            'clf': [MultinomialNB()],\n",
    "        },\n",
    "        {\n",
    "            'preprocessor__text__vect': [TfidfVectorizer(), CountVectorizer()],\n",
    "            'clf': [XGBClassifier(objective='multi:softprob', eval_metric='mlogloss', use_label_encoder=False)],\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    grid = GridSearchCV(\n",
    "        pipeline,\n",
    "        param_grid=param_grid,\n",
    "        cv=5,\n",
    "        scoring=['accuracy','f1_macro', 'roc_auc_ovr'],\n",
    "        refit='f1_macro',\n",
    "        n_jobs=-1,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    print(\"Fitting to pipeline\")\n",
    "    mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "    mlflow.sklearn.autolog()\n",
    "    mlflow.set_experiment(experiment_id=\"1\")\n",
    "    with mlflow.start_run():\n",
    "        mlflow.log_param(\"fields\",'-'.join(fields_to_test))\n",
    "        grid.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Best estimator:\", grid.best_estimator_)\n",
    "    print(\"Best CV score:\", grid.best_score_)\n",
    "    print(\"Estimating performance on test set\")\n",
    "    y_pred = grid.predict(X_test)\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85df2794",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_df = pd.DataFrame(grid.cv_results_)\n",
    "print(cv_df.columns)\n",
    "cv_df[['params', 'mean_test_score', 'std_test_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3bc0b33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time',\n",
      "       'param_clf', 'param_preprocessor__text__vect', 'params',\n",
      "       'split0_test_score', 'split1_test_score', 'split2_test_score',\n",
      "       'split3_test_score', 'split4_test_score', 'mean_test_score',\n",
      "       'std_test_score', 'rank_test_score'],\n",
      "      dtype='object')\n",
      "                                              params  mean_test_score  \\\n",
      "0  {'clf': RandomForestClassifier(), 'preprocesso...         0.427614   \n",
      "1  {'clf': RandomForestClassifier(), 'preprocesso...         0.425714   \n",
      "2  {'clf': LogisticRegression(max_iter=1000), 'pr...         0.456627   \n",
      "3  {'clf': LogisticRegression(max_iter=1000), 'pr...         0.436991   \n",
      "4  {'clf': MultinomialNB(), 'preprocessor__text__...         0.421585   \n",
      "5  {'clf': MultinomialNB(), 'preprocessor__text__...         0.461814   \n",
      "6  {'clf': XGBClassifier(base_score=None, booster...         0.448392   \n",
      "7  {'clf': XGBClassifier(base_score=None, booster...         0.449732   \n",
      "\n",
      "   std_test_score  \n",
      "0        0.033887  \n",
      "1        0.026822  \n",
      "2        0.020006  \n",
      "3        0.018185  \n",
      "4        0.035317  \n",
      "5        0.027541  \n",
      "6        0.021700  \n",
      "7        0.024835  \n",
      "Mejor params: {'clf': MultinomialNB(), 'preprocessor__text__vect': CountVectorizer()}\n",
      "Mejor score (f1_macro): 0.4618142182834638\n",
      "Best estimator pipeline: Pipeline(steps=[('preprocessor',\n",
      "                 ColumnTransformer(transformers=[('text',\n",
      "                                                  Pipeline(steps=[('vect',\n",
      "                                                                   CountVectorizer())]),\n",
      "                                                  'Tweet content'),\n",
      "                                                 ('entity',\n",
      "                                                  OneHotEncoder(handle_unknown='ignore'),\n",
      "                                                  ['Entity'])])),\n",
      "                ('clf', MultinomialNB())])\n"
     ]
    }
   ],
   "source": [
    "# Best set of hyperparameters\n",
    "print(\"best params:\", grid.best_params_)\n",
    "print(\"best score (f1):\", grid.best_score_)\n",
    "print(\"Best estimator pipeline:\", grid.best_estimator_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "generative_ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
